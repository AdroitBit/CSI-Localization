{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b60671-6242-47fd-8c26-9abc64dfd52b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanot\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanot/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sn\n",
    "import scipy.io as sio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d38fb-7db1-4fbf-9de9-6725e94b3a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline (No-human) ##\n",
    "filename = \"../CSI_Data_27122023/Horizontal/Q1_01.csv\"\n",
    "\n",
    "data = pd.read_csv(filename,header=None)\n",
    "# Extract the 26th column\n",
    "df = data.iloc[:, 25]\n",
    "\n",
    "csi_data = []\n",
    "\n",
    "for i in range(1,min(2000, len(df))):\n",
    "    # Remove square brackets and split the string\n",
    "    str1 = df[i].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    List = str1.split(\" \")\n",
    "    del List[-1]\n",
    "    csi_values = [float(val) for val in List]\n",
    "\n",
    "    # Append the list of CSI values to the csi_data list\n",
    "    csi_data.append(csi_values)\n",
    "\n",
    "# Convert csi_data to a NumPy array and then to a DataFrame\n",
    "csi_data = np.array(csi_data).T.tolist()\n",
    "csi_data = pd.DataFrame(csi_data)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(csi_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c405d2-7384-4934-a1fe-ce75ef4744c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67183799-872b-4dea-abba-1f6b65d1d4a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'c:\\Users\\yanot\\AppData\\Local\\Programs\\Python\\Python311\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/yanot/AppData/Local/Programs/Python/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# quartile = \"Q1\"\n",
    "# section = \"01\"\n",
    "quartile = \"Q1\"\n",
    "section = \"03\"\n",
    "sampling_range = 20\n",
    "\n",
    "output_list = []\n",
    "\n",
    "for r in range(1, 2):\n",
    "    file_dir = \"../CSI_Data_27122023/Horizontal/\"\n",
    "    name = quartile + \"_\" + section\n",
    "    csv = \".csv\"\n",
    "    name_csv = name + csv\n",
    "    file_name = os.path.join(file_dir, name_csv)\n",
    "    \n",
    "    # Read CSI data from the current file\n",
    "    data_walk = pd.read_csv(file_name, header=None)\n",
    "    df_walk = data_walk.iloc[:, 25]\n",
    "    df_walk = df_walk.dropna()\n",
    "\n",
    "    csi_data_walk = []\n",
    "    \n",
    "    # Iterate over a limited number of rows (e.g., 2000)\n",
    "    for i in range(min(2000, len(df_walk))):\n",
    "        str1 = df_walk.iloc[i].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        # print(str1)\n",
    "        csi_values = [float(val) for val in str1.split(\" \")[1:-1]]  \n",
    "        csi_data_walk.append(csi_values)\n",
    "    del csi_data_walk[0]\n",
    "    # print(csi_data_walk)\n",
    "    csi_data_walk = np.array(csi_data_walk).T.tolist()\n",
    "    csi_data_walk = pd.DataFrame(csi_data_walk)\n",
    "    # print(\"csi_data_walk\\n\",csi_data_walk)\n",
    "\n",
    "    # Calculate the standard deviation for each subcarrier\n",
    "    # output = []\n",
    "    # for k in range(127):\n",
    "    #     subcarrier_std = csi_data_walk.iloc[:, k].rolling(window=sampling_range).std()\n",
    "    #     output.append(subcarrier_std)\n",
    "    # output_list.append(output)\n",
    "    # sd_output = pd.DataFrame(output)\n",
    "    # print(\"output_df\\n\",sd_output.head())\n",
    "    \n",
    "    sampling_range = 20\n",
    "    output = []\n",
    "    constant=csi_data.mean(axis=1)\n",
    "    for k in range(126):\n",
    "        subcarrier = []\n",
    "        for i in range(0,len(csi_data)-sampling_range):\n",
    "            temp_data = []\n",
    "            for j in range(i, i + sampling_range):\n",
    "                temp_data.append(math.pow(csi_data_walk[j][k] - constant[k],2))\n",
    "            subcarrier.append(math.sqrt(sum(temp_data)/sampling_range))\n",
    "        output.append(subcarrier)\n",
    "    output_list.append(output)\n",
    "    sd_output = pd.DataFrame(output)\n",
    "    print(\"output_df\\n\",sd_output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65c576-26e5-4ca1-95a5-7dbc056c1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array = np.array(output_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b9e92-e586-4a21-97f7-48f38edad44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(sd_output),min(sd_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72105af9-a204-40d0-96bd-e1749a16a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sn.heatmap(sd_output, cmap=\"jet\", vmin=5, vmax=20)\n",
    "plt.savefig(name + \".jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cacf5f0-2b52-4377-a67b-246653944a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_array[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09484214-fd8d-42b9-954f-172ef6679bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_reshape = output_array.reshape(output_array.shape[0], -1)\n",
    "np.savetxt(\"csi_txrx.csv\", output_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee3924-a348-47f6-8896-89fc8df351e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_txrx = np.loadtxt(\"./csi_txrx.csv\")\n",
    "load_rxtx = np.loadtxt(\"./csi_rxtx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f60cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_rxtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf42f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(load_txrx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86be500-1359-4b50-8e39-a4470e802aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi_txrx= load_txrx.reshape(output_array.shape[0], output_array.shape[1], output_array.shape[2])\n",
    "csi_rxtx= load_rxtx.reshape(output_array.shape[0], output_array.shape[1], output_array.shape[2])\n",
    "\n",
    "# csi_txrx= load_txrx.reshape(output_array.shape[0], output_array.shape[1])\n",
    "# csi_rxtx= load_rxtx.reshape(output_array.shape[0], output_array.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f119f6c-02e1-49b8-bd16-ccb9785e0590",
   "metadata": {},
   "outputs": [],
   "source": [
    "csi = np.concatenate((csi_txrx, csi_rxtx),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efd9c3b-e1a4-4b78-a8fa-298a91b896ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeros = np.zeros(30)\n",
    "ones = np.ones(30)\n",
    "answer = np.concatenate((zeros, ones))\n",
    "\n",
    "\n",
    "print(zeros)\n",
    "print(ones)\n",
    "print(\"answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78aaa2-f453-4f83-bc14-7af9dcfe91c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "permutation = np.random.permutation(len(csi))\n",
    "print(permutation)\n",
    "# Use the same permutation to shuffle both arrays\n",
    "shuffled_csi = csi[permutation]\n",
    "shuffled_answer = answer[permutation]\n",
    "\n",
    "print(\"shuffle_csi :\",shuffled_csi)\n",
    "print(\"shuffle_csi shape :\",shuffled_csi.shape)\n",
    "\n",
    "print(\"shuffle_answer :\",shuffled_answer)\n",
    "print(\"shuffle_answer shape :\",shuffled_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71db6c0e-059b-4362-a14b-c35b1ed34b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = shuffled_csi[:50]\n",
    "x_test = shuffled_csi[50:]\n",
    "y_train = shuffled_answer[:50]\n",
    "y_test = shuffled_answer[50:60]\n",
    "\n",
    "#print data\n",
    "print(\"x_train\")\n",
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "\n",
    "print(\"x_test\")\n",
    "print(x_test)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(\"y_train\")\n",
    "print(y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"y_test\")\n",
    "print(y_test)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdedd02-0790-425f-97d0-68841516ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "print(x_train.max())\n",
    "print(x_test.max())\n",
    "\n",
    "x_train = x_train / x_train.max()\n",
    "x_test = x_test / x_test.max()\n",
    "print(\"x_train:\")\n",
    "print(x_train)\n",
    "print()\n",
    "print(\"x_test:\")\n",
    "print(x_test)\n",
    "# x_train = x_train.reshape(-1, 126, 100)\n",
    "# x_test = x_test.reshape(-1, 126, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df80e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have preprocessed input data x_train and output data y_train\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(None, 2)),  # Input shape for two streams of CSI data\n",
    "    # Add layers as per your architecture design\n",
    "    # Example:\n",
    "    # keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu'),\n",
    "    # keras.layers.MaxPooling1D(pool_size=2),\n",
    "    # keras.layers.LSTM(units=64, return_sequences=True),\n",
    "    # keras.layers.Dense(16, activation='relu'),\n",
    "    # keras.layers.Dense(4*4, activation='softmax'),  # Output layer for 4x4 array\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(4*4, activation='sigmoid'),  # Output layer for 4x4 array\n",
    "    keras.layers.Reshape((4, 4))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Binary cross-entropy for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)  # Adjust batch size and epochs as needed\n",
    "\n",
    "# Evaluate the model if needed\n",
    "# model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5af2b-2133-4055-8e6b-16b0d6f1bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d0439-88b7-4fb3-b938-a21c86dfb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ad202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD Code\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(126, 100)),\n",
    "    keras.layers.Dense(8, activation='sigmoid'),\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92bbb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
